{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def max_connect(x, y, viterbi_matrix, emission, transmission_matrix):\n",
    "\tmax = -99999\n",
    "\tpath = -1\n",
    "\tfor k in range(len(tags)):\n",
    "\t\tval = viterbi_matrix[k][x-1] * transmission_matrix[k][y]\n",
    "\t\tif val * emission > max:\n",
    "\t\t\tmax = val\n",
    "\t\t\tpath = k\n",
    "\treturn max, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>\\\\START\\r\\n', 'Published\\\\PROPN\\r\\n', 'on\\\\PROPN\\r\\n', '2015-11-19\\\\NUM\\r\\n', '11:02:15\\\\NUM\\r\\n', 'விண்வெளியில்\\\\NOUN\\r\\n', 'இருந்து\\\\ADP\\r\\n', 'இன்று\\\\ADV\\r\\n', 'முற்பகல்\\\\NOUN\\r\\n', '11.45\\\\NUM\\r\\n']\n",
      "127799\n",
      "['PROPN', 'NUM', 'NOUN', 'ADP', 'ADV', 'VERB', 'CCONJ', 'DET', 'PUNCT', 'ADJ', 'PRON', 'VAUX', 'PART', 'NEG', 'UT', 'WQ', 'INTF']\n",
      "20667\n",
      "[14037, 5552, 59040, 975, 4041, 15339, 2969, 1093, 1846, 4457, 4310, 884, 169, 83, 118, 14, 13]\n",
      "6438\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filepath = \"tamil_training.txt\"\n",
    "language = \"tamil\"\n",
    "exclude = [\"<s>\", \"</s>\", \"START\", \"END\"]\n",
    "wordtypes = []\n",
    "tagscount = []\n",
    "\t# Open training file to read the contents\n",
    "f = codecs.open(filepath, 'r', encoding='utf-8')\n",
    "file_contents = f.readlines()\n",
    "print(file_contents[:10])\t\t#<-------------------------------------\n",
    "print(len(file_contents))\t\t#<-------------------------------------\n",
    "count=0\n",
    "for x in range(len(tags)):\n",
    "\ttagscount.append(0)\n",
    "for x in range(len(file_contents)):\n",
    "\tline = file_contents.pop(0).strip().split('\\\\')\n",
    "\t\n",
    "\n",
    "\tfor i, word in enumerate(line):  #for has 2 itertations the first the actual word (i=0) and then the tag (i=1)\n",
    "\t\tif i == 0:\n",
    "\t\t\tif word in exclude:\n",
    "\t\t\t\tcount+=1\n",
    "\t\t\tif word not in wordtypes and word not in exclude:\n",
    "\t\t\t\twordtypes.append(word)\n",
    "\t\telse:\n",
    "\t\t\tif word not in tags and word not in exclude:\n",
    "\t\t\t\ttags.append(word)\n",
    "\t\t\t\ttagscount.append(0)\n",
    "\t\t\t\ttagscount[tags.index(word)]+=1\n",
    "\t\t\tif word in tags and word not in exclude:\n",
    "\t\t\t\ttagscount[tags.index(word)] += 1\n",
    "\t\t\n",
    "f.close()\n",
    "print(tags)\n",
    "print(len(wordtypes))\t#<-------------------------------------\n",
    "print(tagscount)\n",
    "print(count//2)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emission_matrix = []\n",
    "transmission_matrix = []\n",
    "\t# Initialize emission matrix\n",
    "for x in range(len(tags)):\n",
    "\temission_matrix.append([])\n",
    "\tfor y in range(len(wordtypes)):\n",
    "\t\temission_matrix[x].append(0)\n",
    "\t# Initialize transmission matrix\n",
    "for x in range(len(tags)):\n",
    "\ttransmission_matrix.append([])\n",
    "\tfor y in range(len(tags)):\n",
    "\t\ttransmission_matrix[x].append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>\\\\START\\r\\n', 'Published\\\\PROPN\\r\\n', 'on\\\\PROPN\\r\\n', '2015-11-19\\\\NUM\\r\\n', '11:02:15\\\\NUM\\r\\n', 'விண்வெளியில்\\\\NOUN\\r\\n', 'இருந்து\\\\ADP\\r\\n', 'இன்று\\\\ADV\\r\\n', 'முற்பகல்\\\\NOUN\\r\\n', '11.45\\\\NUM\\r\\n']\n"
     ]
    }
   ],
   "source": [
    "f = codecs.open(filepath ,'r', encoding='utf-8')\n",
    "file_contents = f.readlines()\n",
    "print(file_contents[:10])\t\t#<-------------------------------------\n",
    "\t# Update emission and transmission matrix with appropriate counts\n",
    "row_id = -1\n",
    "for x in range(len(file_contents)):\n",
    "\tline = file_contents.pop(0).strip().split('\\\\')\n",
    "\tif line[0] not in exclude:\n",
    "\t\tcol_id = wordtypes.index(line[0])\n",
    "\t\tprev_row_id = row_id\n",
    "\t\ttry:\n",
    "\t\t\trow_id = tags.index(line[1])\n",
    "\t\texcept:\n",
    "\t\t\tprint(x)\n",
    "\t\t\tbreak\n",
    "\t\temission_matrix[row_id][col_id] += 1\n",
    "\t\tif prev_row_id != -1:\n",
    "\t\t\ttransmission_matrix[prev_row_id][row_id] += 1\n",
    "\telse:\n",
    "\t\trow_id = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(tags)):\n",
    "\tfor y in range(len(wordtypes)):\n",
    "\t\tif tagscount[x] != 0:\n",
    "\t\t\temission_matrix[x][y] = float(emission_matrix[x][y]) / tagscount[x]\n",
    "\t# Divide each entry in transmission matrix by appropriate tag count to store probabilities in each entry instead of just count\n",
    "for x in range(len(tags)):\n",
    "\tfor y in range(len(tags)):\n",
    "\t\tif tagscount[x] != 0:\n",
    "\t\t\ttransmission_matrix[x][y] = float(transmission_matrix[x][y]) / tagscount[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716\n",
      "\n",
      "Kindly check tamil_tags.txt file for POS tags.\n"
     ]
    }
   ],
   "source": [
    "testpath = \"tamil_testing_sentences.txt\"\n",
    "file_test = codecs.open(testpath, 'r', encoding='utf-8')\n",
    "test_input = file_test.readlines()\n",
    "print(len(test_input))\n",
    "\t# Declare variables for test words and pos tags\n",
    "test_words = []\n",
    "pos_tags = []\n",
    "\t# Create an output file to write the output tags for each sentences\n",
    "file_output = codecs.open(language +\"_tags.txt\", 'w', 'utf-8')\n",
    "file_output.close()\n",
    "\t# For each line POS tags are computed\n",
    "for j in range(len(test_input)):\n",
    "\ttest_words = []\n",
    "\tpos_tags = []\n",
    "\tline = test_input.pop(0).strip().split(' ')\n",
    "\tfor word in line:\n",
    "\t\ttest_words.append(word)\n",
    "\t\tpos_tags.append(-1)\n",
    "\tviterbi_matrix = []\n",
    "\tviterbi_path = []\n",
    "\t\t# Initialize viterbi matrix of size |tags| * |no of words in test sentence|\n",
    "\tfor x in range(len(tags)):\n",
    "\t\tviterbi_matrix.append([])\n",
    "\t\tviterbi_path.append([])\n",
    "\t\tfor y in range(len(test_words)):\n",
    "\t\t\tviterbi_matrix[x].append(0)\n",
    "\t\t\tviterbi_path[x].append(0)\n",
    "\t\t# Update viterbi matrix column wise\n",
    "\tfor x in range(len(test_words)):\n",
    "\t\tfor y in range(len(tags)):\n",
    "\t\t\tif test_words[x] in wordtypes:\n",
    "\t\t\t\tword_index = wordtypes.index(test_words[x])\n",
    "\t\t\t\ttag_index = tags.index(tags[y])\n",
    "\t\t\t\temission = emission_matrix[tag_index][word_index]\n",
    "\t\t\telse:\n",
    "\t\t\t\temission = 0.001\n",
    "\t\t\tif x > 0:\n",
    "\t\t\t\tmax, viterbi_path[y][x] = max_connect(x, y, viterbi_matrix, emission, transmission_matrix)\n",
    "\t\t\telse:\n",
    "\t\t\t\tmax = 1\n",
    "\t\t\tviterbi_matrix[y][x] = emission * max\n",
    "\t\t# Identify the max probability in last column i.e. best tag for last word in test sentence\n",
    "\tmaxval = -999999\n",
    "\tmaxs = -1\n",
    "\tfor x in range(len(tags)):\n",
    "\t\tif viterbi_matrix[x][len(test_words)-1] > maxval:\n",
    "\t\t\tmaxval = viterbi_matrix[x][len(test_words)-1]\n",
    "\t\t\tmaxs = x\n",
    "\t\t# Backtrack and identify best tags for each words\n",
    "\tfor x in range(len(test_words)-1, -1, -1):\n",
    "\t\tpos_tags[x] = maxs\n",
    "\t\tmaxs = viterbi_path[maxs][x]\n",
    "\t\t# Display POS Tags in the console.\n",
    "\t\t# print pos_tags\n",
    "\t\t# Print output to the file.\t\n",
    "\tfile_output = codecs.open(language +\"_tags.txt\", 'a', 'utf-8')\n",
    "\tfor i, x in enumerate(pos_tags):\n",
    "\t\tfile_output.write(tags[x] + \" \")\n",
    "\tfile_output.write(\"\\n\")\t\n",
    "f.close()\n",
    "file_output.close()\n",
    "file_test.close()\n",
    "\n",
    "print (\"\\nKindly check \" + language + \"_tags.txt file for POS tags.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
