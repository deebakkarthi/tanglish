{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from nltk import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extract_features(sentence, index):\n",
    "  return {\n",
    "      'word':sentence[index],\n",
    "      'is_first':index==0,\n",
    "      'is_last':index ==len(sentence)-1,\n",
    "      'prefix-1':sentence[index][0],\n",
    "      'prefix-2':sentence[index][:2],\n",
    "      'prefix-3':sentence[index][:3],\n",
    "      'prefix-3':sentence[index][:4],\n",
    "      'suffix-1':sentence[index][-1],\n",
    "      'suffix-2':sentence[index][-2:],\n",
    "      'suffix-3':sentence[index][-3:],\n",
    "      'suffix-3':sentence[index][-4:],\n",
    "      'prev_word':'' if index == 0 else sentence[index-1],\n",
    "      'next_word':'' if index < len(sentence) else sentence[index+1],\n",
    "      'has_hyphen': '-' in sentence[index],\n",
    "      'is_numeric': sentence[index].isdigit(),\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./pos_crf_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "    print(type(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dataset(sentence):\n",
    "  tmp = []\n",
    "  for index in range(len(sentence)):\n",
    "      tmp.append(extract_features(sentence, index)),\n",
    "  return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dataset(corpus: str):\n",
    "    sentences = sent_tokenize(corpus)\n",
    "    sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    X = []\n",
    "    for sentence in sentences:\n",
    "        tmp = []\n",
    "        for i in range(len(sentence)):\n",
    "            tmp.append(extract_features(sentence, i))\n",
    "        X.append(tmp)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt = \"இல்­லையா என்­பதை மக்கள் முன்­னி­லையில் குறிப்­பிட வேண்டும் .  அதேபோல் இம்­முறை வரவு–செலவு திட்டமானது மக்­க­ளுக்கு சிறி­த­ளவு நிவா­ரணம் அம்­சங்கள் சிலவும் உள்­ளன .  அதனால் இதனை தோற்கடிப்பதால் மாத்திரம் மாற்றத்தை ஏற்படுத்த முடியாது.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transform_to_dataset(input_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [transform_to_dataset(input_txt)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_features([\"இல்­லையா\"], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ner_crf_model.pkl\", \"rb\") as f:\n",
    "    ner_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ner_features(sentence, index):\n",
    "    word = sentence[index]\n",
    "    return {\n",
    "        'word': word,\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'prefix-1': \"\" if not word else word[0],\n",
    "        'prefix-2': word[:2],\n",
    "        'prefix-3': word[:3],\n",
    "        'prefix-4': word[:4],\n",
    "        'suffix-1': \"\" if not word else word[-1],\n",
    "        'suffix-2': word[-2:],\n",
    "        'suffix-3': word[-3:],\n",
    "        'suffix-4': word[-4:],\n",
    "        'prev_word': '' if index == 0 else sentence[index - 1][0],\n",
    "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1][0],\n",
    "        'has_hyphen': '-' in word,\n",
    "        'is_numeric': word.isdigit(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_ner_dataset(corpus: str):\n",
    "    sentences = sent_tokenize(corpus)\n",
    "    sentences = [word_tokenize(sentence) for sentence in sentences]\n",
    "    X = []\n",
    "    for sentence in sentences:\n",
    "        tmp = []\n",
    "        for i in range(len(sentence)):\n",
    "            tmp.append(extract_ner_features(sentence, i))\n",
    "        X.append(tmp)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_txt += \"இந்தியா,ஆஸ்திரேலியா, இலங்கை.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transform_to_ner_dataset(input_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_model.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./lstm_tokenizer.pkl\", \"rb\") as f:\n",
    "    lstm_tokenizer_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_tokenizer_model.texts_to_sequences([\"mass thala ajith vijay rajini\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pad_sequences(lstm_tokenizer_model.texts_to_sequences([\"mass thala ajith vijay rajini\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = load_model(\"./llm_lstm_model.keras/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.predict(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['Mixed_feelings','Negative','Positive','unknown_state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred_class = []\n",
    "for item in lstm_model.predict(tmp):\n",
    "  index = np.argmax(item)\n",
    "  pred_class.append(classes[index])\n",
    "  #pred_class.append(index)\n",
    "\n",
    "print(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda x: classes[np.argmax(x)], lstm_model.predict(tmp)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class INTENT_CLASSIFIER(nn.Module):\n",
    "\n",
    "  def __init__(self, freeze_bert=True):\n",
    "    super(INTENT_CLASSIFIER, self).__init__()\n",
    "\n",
    "    self.bert_layers = BertModel.from_pretrained('bert-base-multilingual-cased',return_dict=False)\n",
    "    self.linear1 = nn.Linear(768, 300)\n",
    "    self.linear11 = nn.Linear(300, 8)\n",
    "    self.linear2 = nn.Linear(8, 2)\n",
    "    self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    if freeze_bert:\n",
    "      for param in self.bert_layers.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "  def forward(self, token_ids, atten_mask):\n",
    "    \"\"\"Both argument are of shape: batch_size, max_seq_len\"\"\"\n",
    "    _, CLS = self.bert_layers(token_ids, attention_mask = atten_mask)\n",
    "    logits = self.dropout(self.linear1(CLS))\n",
    "    logits = self.dropout(self.linear11(logits))\n",
    "    logits = self.linear2(logits)\n",
    "\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the model\n",
    "model = torch.load(\"./best_model.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deebakkarthi/.local/src/tanglishServer/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file=\"./tamil_dev.csv\"\n",
    "test_set = ATIS(file_name = test_file, max_token_len=120, translit_prob=0, shuffle_prob=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(test_set, batch_size = 64, num_workers =4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the test accuracy\n",
    "def test():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "  y_test_prediction = []\n",
    "  y_test_true = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for data in val_loader:\n",
    "          tokens, masks, labels = data\n",
    "\n",
    "          tokens = tokens.to(device)\n",
    "          masks = masks.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          outputs = model(tokens, masks)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels.squeeze()).sum().item()\n",
    "\n",
    "          y_test_true += labels.squeeze().detach().cpu().numpy().tolist()\n",
    "          y_test_prediction += predicted.detach().cpu().numpy().tolist()\n",
    "\n",
    "  print('Test Accuracy: {}%'.format(100 * correct / total))\n",
    "  test_accuracy_value = correct/total\n",
    "  return y_test_true, y_test_prediction, test_accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test_file=\"./tamil_test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ATIS import ATIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_test_set = ATIS(file_name = test_test_file, max_token_len=120, translit_prob=0, shuffle_prob=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  101, 12382, 12822, 12382, 10112, 66325, 33396,   102,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'kannane kanne  milion views',\n",
       " 'Positive')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_test_set[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_test_set, batch_size = 1, num_workers =4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 120])\n",
      "torch.Size([1, 120])\n",
      "('yarayellam fdfs ppga ippove ready agitinga',)\n",
      "('Positive',)\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(test_loader, 0):\n",
    "  print(data[0].shape)\n",
    "  print(data[1].shape)\n",
    "  print(data[2])\n",
    "  print(data[3])\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path where model is saved and loaded\n",
    "model_path = 'best_model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deebakkarthi/.local/src/tanglishServer/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from INTENT_CLASSIFIER import INTENT_CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb Cell 55\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y105sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#loading the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y105sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m\"\u001b[39m\u001b[39m./best_model.pth\u001b[39m\u001b[39m\"\u001b[39m, map_location\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#loading the model\n",
    "model = torch.load(\"./best_model.pth\", map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb Cell 56\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y106sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  model.eval()\n",
    "  y_test_prediction = []\n",
    "  y_test_true = []\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for data in test_loader:\n",
    "          tokens, masks, labels = data\n",
    "\n",
    "          tokens = tokens.to(device)\n",
    "          masks = masks.to(device)\n",
    "          labels = labels.to(device)\n",
    "\n",
    "          outputs = model(tokens, masks)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels.squeeze()).sum().item()\n",
    "\n",
    "          y_test_true += labels.squeeze().detach().cpu().numpy().tolist()\n",
    "          y_test_prediction += predicted.detach().cpu().numpy().tolist()\n",
    "\n",
    "  print('Test Accuracy: {}%'.format(100 * correct / total))\n",
    "  test_accuracy_value = correct/total\n",
    "  return y_test_true, y_test_prediction, test_accuracy_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y131sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test()\n",
      "\u001b[1;32m/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb Cell 58\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y131sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y131sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m test_loader:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y131sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         tokens, masks, labels \u001b[39m=\u001b[39m data\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y131sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         tokens \u001b[39m=\u001b[39m tokens\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/deebakkarthi/.local/src/tanglishServer/playground.ipynb#Y131sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         masks \u001b[39m=\u001b[39m masks\u001b[39m.\u001b[39mto(device)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the test accuracy\n",
    "def inference():\n",
    "  model.eval()\n",
    "\n",
    "  query_id_list = []\n",
    "  query_list = []\n",
    "  prediction_list = []\n",
    "  running_sum = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "      for data in test_loader:\n",
    "          tokens, masks, query, query_id = data\n",
    "\n",
    "          query_id_list.append(query_id[0])\n",
    "          query_list.append(query[0])\n",
    "\n",
    "          tokens = tokens.to(device)\n",
    "          masks = masks.to(device)\n",
    "\n",
    "          outputs = model(tokens, masks)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          running_sum+=predicted.detach().cpu().item()\n",
    "\n",
    "          prediction_list.append('off' if predicted==1 else 'not')\n",
    "          # break\n",
    "\n",
    "          # y_test_true += labels.squeeze().detach().cpu().numpy().tolist()\n",
    "          # y_test_prediction += predicted.detach().cpu().numpy().tolist()\n",
    "\n",
    "  # print('Test Accuracy: {}%'.format(100 * correct / total))\n",
    "  # test_accuracy_value = correct/total\n",
    "  return running_sum, query_id_list, query_list, prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTENT_CLASSIFIER(\n",
       "  (bert_layers): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear1): Linear(in_features=768, out_features=300, bias=True)\n",
       "  (linear11): Linear(in_features=300, out_features=8, bias=True)\n",
       "  (linear2): Linear(in_features=8, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
